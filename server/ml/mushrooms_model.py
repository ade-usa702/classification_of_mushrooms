import os
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
import joblib
from datetime import datetime
from ml.prepared_data import prepared_data
from utils.logger import log as logger


class MushroomsModel:
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥—Ä–∏–±–æ–≤"""    
    def __init__(self, filename):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

        Args:
            filename: –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª .csv/.zip
        """        
        self.df = pd.read_csv(filename)
        self.scaler = MinMaxScaler()
        self.model = RandomForestClassifier(random_state=42, n_estimators=150, min_samples_split=10)
        self.pipeline = None
    
    def preprocess_data(self):
        """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö"""        
        try:
            df = prepared_data(self.df)
            # –¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é(target) –∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ(–ø—Ä–∏–∑–Ω–∞–∫–∏)
            X = df.drop('class', axis=1)
            y = df['class']
            cat = [i for i in X.select_dtypes(include='object').columns]
            numeric_transformer = Pipeline(steps=[
                ('scaler', self.scaler)
            ])
            categorical_transformer = Pipeline(steps=[
                ('o_encoder', OneHotEncoder(handle_unknown='ignore'))
            ])
            preprocessor = ColumnTransformer(
                transformers=[
                    ('num', numeric_transformer, ["square-mushroom"]),
                    ('cat', categorical_transformer, cat),
                    ])
            pipeline = Pipeline(steps=[
                ('preprocessor', preprocessor),
                ('classifier', self.model)
                ])
            # –æ—Ç–¥–µ–ª—è–µ–º –≤—ã–±–æ—Ä–∫—É –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é
            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)
            pipeline.fit(X_train, y_train)
            self.pipeline = pipeline
        except Exception as e:
            logger.error(f"‚ùå–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–µ: {e}")

    def fit_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""        
        try:
            artifact = {
                "model": self.pipeline,
                "trained_at": datetime.now().isoformat()

            }
            filename = "mushrooms_model.pkl"
            if os.path.exists(filename):
                logger.warning(f"–§–∞–π–ª {filename} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω")
            joblib.dump(artifact, filename)
            logger.info("üíæ–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ –ø—Ä–æ–µ–∫—Ç–∞")
        except Exception as e:
            logger.error(f"‚ùå–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ .pkl: {e}")
